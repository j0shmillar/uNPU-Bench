library/inference/tflmtag2412_u55tag2411/tensorflow/lite/kernels/kernel_util.cc:113:21:const TfLiteTensor* tflite::GetInput(const TfLiteContext*, const TfLiteNode*, int)	4	static
library/inference/tflmtag2412_u55tag2411/tensorflow/lite/kernels/kernel_util.cc:118:14:TfLiteStatus tflite::GetInputSafe(const TfLiteContext*, const TfLiteNode*, int, const TfLiteTensor**)	16	static
library/inference/tflmtag2412_u55tag2411/tensorflow/lite/kernels/kernel_util.cc:123:15:TfLiteTensor* tflite::GetVariableInput(TfLiteContext*, const TfLiteNode*, int)	8	static
library/inference/tflmtag2412_u55tag2411/tensorflow/lite/kernels/kernel_util.cc:130:15:TfLiteTensor* tflite::GetOutput(TfLiteContext*, const TfLiteNode*, int)	4	static
library/inference/tflmtag2412_u55tag2411/tensorflow/lite/kernels/kernel_util.cc:140:14:TfLiteStatus tflite::GetOutputSafe(const TfLiteContext*, const TfLiteNode*, int, TfLiteTensor**)	16	static
library/inference/tflmtag2412_u55tag2411/tensorflow/lite/kernels/kernel_util.cc:150:21:const TfLiteTensor* tflite::GetOptionalInputTensor(const TfLiteContext*, const TfLiteNode*, int)	4	static
library/inference/tflmtag2412_u55tag2411/tensorflow/lite/kernels/kernel_util.cc:292:14:TfLiteStatus tflite::GetQuantizedConvolutionMultipler(TfLiteContext*, const TfLiteTensor*, const TfLiteTensor*, const TfLiteTensor*, TfLiteTensor*, double*)	24	static
library/inference/tflmtag2412_u55tag2411/tensorflow/lite/kernels/kernel_util.cc:329:14:TfLiteStatus tflite::GetQuantizedConvolutionMultipler(TfLiteContext*, const TfLiteTensor*, const TfLiteTensor*, TfLiteTensor*, double*)	24	static
library/inference/tflmtag2412_u55tag2411/tensorflow/lite/kernels/kernel_util.cc:389:14:TfLiteStatus tflite::CalculateActivationRangeQuantized(TfLiteContext*, TfLiteFusedActivation, TfLiteTensor*, int32_t*, int32_t*)	24	static
library/inference/tflmtag2412_u55tag2411/tensorflow/lite/kernels/kernel_util.cc:215:14:TfLiteStatus tflite::PopulateConvolutionQuantizationParams(TfLiteContext*, const TfLiteTensor*, const TfLiteTensor*, const TfLiteTensor*, TfLiteTensor*, const TfLiteFusedActivation&, int32_t*, int*, int32_t*, int32_t*, int32_t*, int32_t*, int)	128	static
library/inference/tflmtag2412_u55tag2411/tensorflow/lite/kernels/kernel_util.cc:200:14:TfLiteStatus tflite::PopulateConvolutionQuantizationParams(TfLiteContext*, const TfLiteTensor*, const TfLiteTensor*, const TfLiteTensor*, TfLiteTensor*, const TfLiteFusedActivation&, int32_t*, int*, int32_t*, int32_t*, int32_t*, int32_t*)	56	static
library/inference/tflmtag2412_u55tag2411/tensorflow/lite/kernels/kernel_util.cc:413:6:bool tflite::HaveSameShapes(const TfLiteTensor*, const TfLiteTensor*)	8	static
library/inference/tflmtag2412_u55tag2411/tensorflow/lite/kernels/kernel_util.cc:530:5:int tflite::TfLiteTypeGetSize(TfLiteType)	0	static
library/inference/tflmtag2412_u55tag2411/tensorflow/lite/kernels/kernel_util.cc:578:6:bool tflite::IsMobilePlatform()	0	static
library/inference/tflmtag2412_u55tag2411/tensorflow/lite/kernels/kernel_util.cc:588:6:bool tflite::HasUnspecifiedDimension(const TfLiteTensor*)	0	static
