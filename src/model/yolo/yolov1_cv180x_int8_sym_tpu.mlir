#loc = loc(unknown)
module @yolov1 attributes {module.FLOPs = 43289280 : i64, module.addr_mode = "basic", module.asymmetric = false, module.chip = "cv180x", module.cores = 1 : i64, module.devices = 1 : i64, module.high_precision = false, module.mode = "INT8", module.platform = "ONNX", module.q_group_size = 0 : i64, module.state = "TPU_LOWERED", module.top_run_mode = "STATIC", module.weight_file = "yolov1_tpu_lowered_cv180x_int8_sym_weight.npz"} {
  func.func @main(%arg0: tensor<1x3x96x96xf32> loc(unknown)) -> (tensor<1x12x12x10xf32>, tensor<1x12x12x2xf32>, tensor<1x12x12x12xf32>) {
    %0 = "top.None"() : () -> none loc(#loc)
    %1 = "top.Input"(%arg0) {channel_format = "nchw", do_preprocess = true, keep_aspect_ratio = false, keep_ratio_mode = "letterbox", mean = [0.000000e+00, 0.000000e+00, 0.000000e+00], pad_type = "center", pad_value = 0 : i64, pixel_format = "bgr", scale = [1.000000e+00, 1.000000e+00, 1.000000e+00]} : (tensor<1x3x96x96xf32>) -> tensor<1x3x96x96x!quant.calibrated<f32<-4.2516036000000001:4.2516036000000001>>> loc(#loc1)
    %2 = "tpu.GenericCpu"(%1) {cpu_op_name = "quant", param = {from = "FP32", scale = 29.8710804 : f32, to = "INT8"}} : (tensor<1x3x96x96x!quant.calibrated<f32<-4.2516036000000001:4.2516036000000001>>>) -> tensor<1x3x96x96x!quant.uniform<i8:f32, 0.033477193700787403>> loc(#loc2)
    %3 = "top.Weight"() : () -> tensor<16x3x3x3xsi8> loc(#loc3)
    %4 = "tpu.Conv2D"(%2, %3, %0) {coeff_merged = false, dilations = [1, 1], do_relu = true, do_winograd = false, dynweight_reorderd = false, group = 1 : i64, kernel_shape = [3, 3], kernel_zp = 0 : i64, multiplier = [1352728448, 1331523840, 1333214848, 1348767488, 1293920512, 1378210688, 1359031936, 1309235712, 1351388288, 1366352256, 1171502208, 1328503680, 1361016832, 1385805568, 1309924352, 1387734144], pads = [1, 1, 1, 1], quant_mode = #tpu<rq_mode QDM>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, rshift = [8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8], strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = false} : (tensor<1x3x96x96x!quant.uniform<i8:f32, 0.033477193700787403>>, tensor<16x3x3x3xsi8>, none) -> tensor<1x16x96x96x!quant.uniform<i8:f32, 0.0200665125984252>> loc(#loc4)
    %5 = "tpu.Pool2D"(%4) {count_include_pad = false, do_relu = false, first_round_mode = #tpu<round_mode HalfAwayFromZero>, is_adaptive = false, keepdims = true, kernel_shape = [2, 2], pad_value = 0 : i64, pads = [0, 0, 0, 0], pool_mode = #tpu<pool_mode Max>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfAwayFromZero>, strides = [2, 2]} : (tensor<1x16x96x96x!quant.uniform<i8:f32, 0.0200665125984252>>) -> tensor<1x16x48x48x!quant.uniform<i8:f32, 0.0200665125984252>> loc(#loc5)
    %6 = "top.Weight"() : () -> tensor<16x16x3x3xsi8> loc(#loc6)
    %7 = "tpu.Conv2D"(%5, %6, %0) {coeff_merged = false, dilations = [1, 1], do_relu = true, do_winograd = false, dynweight_reorderd = false, group = 1 : i64, kernel_shape = [3, 3], kernel_zp = 0 : i64, multiplier = [1241882496, 1237016192, 1238214016, 1224485760, 1242414208, 1241854976, 1243396992, 1242065280, 1228689024, 1237284480, 1241751680, 1213425792, 1233890176, 1225682944, 1239478272, 1237240960], pads = [1, 1, 1, 1], quant_mode = #tpu<rq_mode QDM>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, rshift = [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9], strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = false} : (tensor<1x16x48x48x!quant.uniform<i8:f32, 0.0200665125984252>>, tensor<16x16x3x3xsi8>, none) -> tensor<1x16x48x48x!quant.uniform<i8:f32, 0.011605399212598426>> loc(#loc7)
    %8 = "tpu.Pool2D"(%7) {count_include_pad = false, do_relu = false, first_round_mode = #tpu<round_mode HalfAwayFromZero>, is_adaptive = false, keepdims = true, kernel_shape = [2, 2], pad_value = 0 : i64, pads = [0, 0, 0, 0], pool_mode = #tpu<pool_mode Max>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfAwayFromZero>, strides = [2, 2]} : (tensor<1x16x48x48x!quant.uniform<i8:f32, 0.011605399212598426>>) -> tensor<1x16x24x24x!quant.uniform<i8:f32, 0.011605399212598426>> loc(#loc8)
    %9 = "top.Weight"() : () -> tensor<16x16x1x1xsi8> loc(#loc9)
    %10 = "tpu.Conv2D"(%8, %9, %0) {coeff_merged = false, dilations = [1, 1], do_relu = true, do_winograd = false, dynweight_reorderd = false, group = 1 : i64, kernel_shape = [1, 1], kernel_zp = 0 : i64, multiplier = [1273712512, 1289066496, 1312741248, 1302948864, 1336624000, 1320711168, 1300194048, 1252559744, 1255480704, 1303699712, 1267215232, 1330493184, 1309260800, 1332142592, 1264545280, 1170097792], pads = [0, 0, 0, 0], quant_mode = #tpu<rq_mode QDM>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, rshift = [7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7], strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = false} : (tensor<1x16x24x24x!quant.uniform<i8:f32, 0.011605399212598426>>, tensor<16x16x1x1xsi8>, none) -> tensor<1x16x24x24x!quant.uniform<i8:f32, 0.004694941732283465>> loc(#loc10)
    %11 = "top.Weight"() : () -> tensor<32x16x3x3xsi8> loc(#loc11)
    %12 = "top.Weight"() : () -> tensor<1x32x1x1xi32> loc(#loc12)
    %13 = "tpu.Conv2D"(%10, %11, %12) {coeff_merged = false, dilations = [1, 1], do_relu = true, do_winograd = false, dynweight_reorderd = false, group = 1 : i64, kernel_shape = [3, 3], kernel_zp = 0 : i64, multiplier = [1696288256, 1695703680, 1679061248, 1676642688, 1701039360, 1690596096, 1691706880, 1699294976, 1696083584, 1669955840, 1677918976, 1694956160, 1701171200, 1671855616, 1681881088, 1683553920, 1698109184, 1681240832, 1696605184, 1676334848, 1698473344, 1701249280, 1701465856, 1676282496, 1685538176, 1698856064, 1698638208, 1687358464, 1699491072, 1698190336, 1691531904, 1667012352], pads = [1, 1, 1, 1], quant_mode = #tpu<rq_mode QDM>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, rshift = [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9], strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x16x24x24x!quant.uniform<i8:f32, 0.004694941732283465>>, tensor<32x16x3x3xsi8>, tensor<1x32x1x1xi32>) -> tensor<1x32x24x24x!quant.uniform<i8:f32, 0.0019906858267716536>> loc(#loc13)
    %14 = "top.Weight"() : () -> tensor<16x32x1x1xsi8> loc(#loc14)
    %15 = "top.Weight"() : () -> tensor<1x16x1x1xi32> loc(#loc15)
    %16 = "tpu.Conv2D"(%13, %14, %15) {coeff_merged = false, dilations = [1, 1], do_relu = true, do_winograd = false, dynweight_reorderd = false, group = 1 : i64, kernel_shape = [1, 1], kernel_zp = 0 : i64, multiplier = [1462390912, 1496150400, 1452861952, 1467115648, 1454615808, 1391888512, 1462812800, 1491228288, 1489132544, 1473846656, 1447129216, 1421046656, 1453946624, 1510010368, 1491393152, 1447363456], pads = [0, 0, 0, 0], quant_mode = #tpu<rq_mode QDM>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, rshift = [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9], strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x32x24x24x!quant.uniform<i8:f32, 0.0019906858267716536>>, tensor<16x32x1x1xsi8>, tensor<1x16x1x1xi32>) -> tensor<1x16x24x24x!quant.uniform<i8:f32, 0.0020158385826771655>> loc(#loc16)
    %17 = "top.Weight"() : () -> tensor<32x16x3x3xsi8> loc(#loc17)
    %18 = "top.Weight"() : () -> tensor<1x32x1x1xi32> loc(#loc18)
    %19 = "tpu.Conv2D"(%16, %17, %18) {coeff_merged = false, dilations = [1, 1], do_relu = true, do_winograd = false, dynweight_reorderd = false, group = 1 : i64, kernel_shape = [3, 3], kernel_zp = 0 : i64, multiplier = [1239756672, 1226933632, 1224381056, 1227912320, 1242898176, 1217929216, 1228809728, 1240990720, 1234024192, 1241352192, 1226821120, 1214282112, 1235148800, 1243578240, 1220998656, 1241543040, 1227591936, 1232162176, 1232590336, 1229249024, 1242306560, 1230430336, 1240496384, 1242256384, 1238263040, 1233022848, 1243810304, 1239170048, 1244144128, 1244361728, 1235603328, 1242937600], pads = [1, 1, 1, 1], quant_mode = #tpu<rq_mode QDM>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, rshift = [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9], strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x16x24x24x!quant.uniform<i8:f32, 0.0020158385826771655>>, tensor<32x16x3x3xsi8>, tensor<1x32x1x1xi32>) -> tensor<1x32x24x24x!quant.uniform<i8:f32, 0.0011684055118110236>> loc(#loc19)
    %20 = "top.Weight"() : () -> tensor<16x32x1x1xsi8> loc(#loc20)
    %21 = "top.Weight"() : () -> tensor<1x16x1x1xi32> loc(#loc21)
    %22 = "tpu.Conv2D"(%19, %20, %21) {coeff_merged = false, dilations = [1, 1], do_relu = true, do_winograd = false, dynweight_reorderd = false, group = 1 : i64, kernel_shape = [1, 1], kernel_zp = 0 : i64, multiplier = [1307461504, 1336269696, 1327457664, 1384615808, 1312233984, 1394184832, 1382854144, 1388177792, 1349126912, 1329358976, 1194581248, 1383081728, 1386632832, 1394337152, 1339897472, 1356399104], pads = [0, 0, 0, 0], quant_mode = #tpu<rq_mode QDM>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, rshift = [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9], strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x32x24x24x!quant.uniform<i8:f32, 0.0011684055118110236>>, tensor<16x32x1x1xsi8>, tensor<1x16x1x1xi32>) -> tensor<1x16x24x24x!quant.uniform<i8:f32, 0.001282120472440945>> loc(#loc22)
    %23 = "top.Weight"() : () -> tensor<32x16x3x3xsi8> loc(#loc23)
    %24 = "top.Weight"() : () -> tensor<1x32x1x1xi32> loc(#loc24)
    %25 = "tpu.Conv2D"(%22, %23, %24) {coeff_merged = false, dilations = [1, 1], do_relu = true, do_winograd = false, dynweight_reorderd = false, group = 1 : i64, kernel_shape = [3, 3], kernel_zp = 0 : i64, multiplier = [1721993984, 1729187712, 1712973824, 1718755328, 1717195136, 1727884288, 1727365760, 1731929600, 1722414720, 1726406656, 1705954560, 1722250752, 1733861760, 1732889472, 1729592064, 1709784832, 1727061376, 1724065024, 1723598080, 1709084160, 1731955712, 1732520704, 1686989952, 1732954496, 1731306880, 1722534400, 1719319040, 1686431104, 1734049920, 1733285504, 1728387328, 1719455232], pads = [1, 1, 1, 1], quant_mode = #tpu<rq_mode QDM>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, rshift = [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10], strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x16x24x24x!quant.uniform<i8:f32, 0.001282120472440945>>, tensor<32x16x3x3xsi8>, tensor<1x32x1x1xi32>) -> tensor<1x32x24x24x!quant.uniform<i8:f32, 0.0010661700787401576>> loc(#loc25)
    %26 = "tpu.Pool2D"(%25) {count_include_pad = false, do_relu = false, first_round_mode = #tpu<round_mode HalfAwayFromZero>, is_adaptive = false, keepdims = true, kernel_shape = [2, 2], pad_value = 0 : i64, pads = [0, 0, 0, 0], pool_mode = #tpu<pool_mode Max>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfAwayFromZero>, strides = [2, 2]} : (tensor<1x32x24x24x!quant.uniform<i8:f32, 0.0010661700787401576>>) -> tensor<1x32x12x12x!quant.uniform<i8:f32, 0.0010661700787401576>> loc(#loc26)
    %27 = "top.Weight"() : () -> tensor<16x32x1x1xsi8> loc(#loc27)
    %28 = "top.Weight"() : () -> tensor<1x16x1x1xi32> loc(#loc28)
    %29 = "tpu.Conv2D"(%26, %27, %28) {coeff_merged = false, dilations = [1, 1], do_relu = true, do_winograd = false, dynweight_reorderd = false, group = 1 : i64, kernel_shape = [1, 1], kernel_zp = 0 : i64, multiplier = [1881639040, 1892348288, 1975697408, 2028575232, 1995768320, 1987001344, 1884146176, 2011887744, 1981812992, 1928402944, 1976225152, 1986431616, 1954447744, 1923992704, 2022923392, 1994651136], pads = [0, 0, 0, 0], quant_mode = #tpu<rq_mode QDM>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, rshift = [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10], strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x32x12x12x!quant.uniform<i8:f32, 0.0010661700787401576>>, tensor<16x32x1x1xsi8>, tensor<1x16x1x1xi32>) -> tensor<1x16x12x12x!quant.uniform<i8:f32, 0.001602588188976378>> loc(#loc29)
    %30 = "top.Weight"() : () -> tensor<32x16x3x3xsi8> loc(#loc30)
    %31 = "top.Weight"() : () -> tensor<1x32x1x1xi32> loc(#loc31)
    %32 = "tpu.Conv2D"(%29, %30, %31) {coeff_merged = false, dilations = [1, 1], do_relu = true, do_winograd = false, dynweight_reorderd = false, group = 1 : i64, kernel_shape = [3, 3], kernel_zp = 0 : i64, multiplier = [1497761792, 1504207616, 1489926400, 1499989504, 1505064832, 1502283008, 1504190592, 1494927104, 1493044736, 1506783872, 1505329152, 1486937600, 1504471552, 1500090624, 1487342848, 1507042688, 1502413440, 1493705216, 1499549568, 1501123200, 1502169088, 1491302272, 1503386752, 1504513024, 1504113152, 1499544064, 1499703168, 1507027840, 1502208896, 1506979840, 1500670848, 1504531072], pads = [1, 1, 1, 1], quant_mode = #tpu<rq_mode QDM>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, rshift = [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10], strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x16x12x12x!quant.uniform<i8:f32, 0.001602588188976378>>, tensor<32x16x3x3xsi8>, tensor<1x32x1x1xi32>) -> tensor<1x32x12x12x!quant.uniform<i8:f32, 0.0015337653543307085>> loc(#loc32)
    %33 = "top.Weight"() : () -> tensor<16x32x1x1xsi8> loc(#loc33)
    %34 = "top.Weight"() : () -> tensor<1x16x1x1xi32> loc(#loc34)
    %35 = "tpu.Conv2D"(%32, %33, %34) {coeff_merged = false, dilations = [1, 1], do_relu = true, do_winograd = false, dynweight_reorderd = false, group = 1 : i64, kernel_shape = [1, 1], kernel_zp = 0 : i64, multiplier = [1720628736, 1803232128, 1798944768, 1737888000, 1771647360, 1791365632, 1555664512, 1701619712, 1629849216, 1787416960, 1791579392, 1698445440, 1611480832, 1762737920, 1790562816, 1728766720], pads = [0, 0, 0, 0], quant_mode = #tpu<rq_mode QDM>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, rshift = [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9], strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x32x12x12x!quant.uniform<i8:f32, 0.0015337653543307085>>, tensor<16x32x1x1xsi8>, tensor<1x16x1x1xi32>) -> tensor<1x16x12x12x!quant.uniform<i8:f32, 0.0012965456692913386>> loc(#loc35)
    %36 = "top.Weight"() : () -> tensor<32x16x3x3xsi8> loc(#loc36)
    %37 = "top.Weight"() : () -> tensor<1x32x1x1xi32> loc(#loc37)
    %38 = "tpu.Conv2D"(%35, %36, %37) {coeff_merged = false, dilations = [1, 1], do_relu = true, do_winograd = false, dynweight_reorderd = false, group = 1 : i64, kernel_shape = [3, 3], kernel_zp = 0 : i64, multiplier = [1095765760, 1099977472, 1105757056, 1107718784, 1106286080, 1102313472, 1092968448, 1100568704, 1083536384, 1106055296, 1106883072, 1096057600, 1095166976, 1106535680, 1097554176, 1103756032, 1103109632, 1105472768, 1103606144, 1097106432, 1096188800, 1099540992, 1105964800, 1105681152, 1097355776, 1094457472, 1099580288, 1097013888, 1103717248, 1095476352, 1084699904, 1102494592], pads = [1, 1, 1, 1], quant_mode = #tpu<rq_mode QDM>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, rshift = [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9], strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x16x12x12x!quant.uniform<i8:f32, 0.0012965456692913386>>, tensor<32x16x3x3xsi8>, tensor<1x32x1x1xi32>) -> tensor<1x32x12x12x!quant.uniform<i8:f32, 8.4408031496062982E-4>> loc(#loc38)
    %39 = "top.Weight"() : () -> tensor<16x32x1x1xsi8> loc(#loc39)
    %40 = "top.Weight"() : () -> tensor<1x16x1x1xi32> loc(#loc40)
    %41 = "tpu.Conv2D"(%38, %39, %40) {coeff_merged = false, dilations = [1, 1], do_relu = true, do_winograd = false, dynweight_reorderd = false, group = 1 : i64, kernel_shape = [1, 1], kernel_zp = 0 : i64, multiplier = [1633235968, 1670381568, 1651794176, 1601043968, 1563550336, 1606128128, 1653669632, 1627259136, 1648045568, 1565162752, 1666376320, 1655465984, 1611271296, 1631278208, 1665625856, 1555530624], pads = [0, 0, 0, 0], quant_mode = #tpu<rq_mode QDM>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, rshift = [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10], strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x32x12x12x!quant.uniform<i8:f32, 8.4408031496062982E-4>>, tensor<16x32x1x1xsi8>, tensor<1x16x1x1xi32>) -> tensor<1x16x12x12x!quant.uniform<i8:f32, 0.0015466204724409449>> loc(#loc41)
    %42 = "top.Weight"() : () -> tensor<32x16x3x3xsi8> loc(#loc42)
    %43 = "top.Weight"() : () -> tensor<1x32x1x1xi32> loc(#loc43)
    %44 = "tpu.Conv2D"(%41, %42, %43) {coeff_merged = false, dilations = [1, 1], do_relu = true, do_winograd = false, dynweight_reorderd = false, group = 1 : i64, kernel_shape = [3, 3], kernel_zp = 0 : i64, multiplier = [1878979456, 1874331776, 1888716416, 1866257024, 1864992128, 1877528576, 1887790464, 1866277504, 1876171392, 1888644224, 1887090176, 1888750464, 1879491712, 1883310336, 1852551040, 1868499712, 1889056000, 1882926848, 1888538880, 1882131328, 1870490496, 1888467840, 1851023488, 1882623616, 1888415872, 1875053312, 1876715904, 1884224896, 1853393280, 1883314432, 1883813504, 1869722752], pads = [1, 1, 1, 1], quant_mode = #tpu<rq_mode QDM>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, rshift = [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10], strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x16x12x12x!quant.uniform<i8:f32, 0.0015466204724409449>>, tensor<32x16x3x3xsi8>, tensor<1x32x1x1xi32>) -> tensor<1x32x12x12x!quant.uniform<i8:f32, 0.0011808425196850392>> loc(#loc44)
    %45 = "top.Weight"() : () -> tensor<16x32x1x1xsi8> loc(#loc45)
    %46 = "top.Weight"() : () -> tensor<1x16x1x1xi32> loc(#loc46)
    %47 = "tpu.Conv2D"(%44, %45, %46) {coeff_merged = false, dilations = [1, 1], do_relu = true, do_winograd = false, dynweight_reorderd = false, group = 1 : i64, kernel_shape = [1, 1], kernel_zp = 0 : i64, multiplier = [1125355648, 1105665152, 1109615488, 1144754432, 1142666752, 1125131008, 1147719040, 2088793984, 1144277632, 1091635968, 1112722432, 1118265216, 1102064512, 1129734016, 1126403072, 1114229504], pads = [0, 0, 0, 0], quant_mode = #tpu<rq_mode QDM>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, rshift = [9, 9, 9, 9, 9, 9, 9, 10, 9, 9, 9, 9, 9, 9, 9, 9], strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x32x12x12x!quant.uniform<i8:f32, 0.0011808425196850392>>, tensor<16x32x1x1xsi8>, tensor<1x16x1x1xi32>) -> tensor<1x16x12x12x!quant.uniform<i8:f32, 0.0015716236220472441>> loc(#loc47)
    %48 = "top.Weight"() : () -> tensor<32x16x3x3xsi8> loc(#loc48)
    %49 = "top.Weight"() : () -> tensor<1x32x1x1xi32> loc(#loc49)
    %50 = "tpu.Conv2D"(%47, %48, %49) {coeff_merged = false, dilations = [1, 1], do_relu = true, do_winograd = false, dynweight_reorderd = false, group = 1 : i64, kernel_shape = [3, 3], kernel_zp = 0 : i64, multiplier = [1992675072, 1971080192, 1977864064, 1988784384, 1987734912, 1995151872, 1989800320, 1966001280, 1992358016, 1993413504, 1986381824, 1981155328, 1986559616, 1995104896, 1988721792, 1995215360, 1994301568, 1982243456, 1990950656, 1994217472, 1986506624, 1965666944, 1948025600, 1979162880, 1985984384, 1930587648, 1952445696, 1983188096, 1976185984, 1988664960, 1990404480, 1994781824], pads = [1, 1, 1, 1], quant_mode = #tpu<rq_mode QDM>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, rshift = [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10], strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x16x12x12x!quant.uniform<i8:f32, 0.0015716236220472441>>, tensor<32x16x3x3xsi8>, tensor<1x32x1x1xi32>) -> tensor<1x32x12x12x!quant.uniform<i8:f32, 0.0011358724409448817>> loc(#loc50)
    %51 = "top.Weight"() : () -> tensor<32x32x1x1xsi8> loc(#loc51)
    %52 = "top.Weight"() : () -> tensor<1x32x1x1xi32> loc(#loc52)
    %53 = "tpu.Conv2D"(%50, %51, %52) {coeff_merged = false, dilations = [1, 1], do_relu = true, do_winograd = false, dynweight_reorderd = false, group = 1 : i64, kernel_shape = [1, 1], kernel_zp = 0 : i64, multiplier = [2063094272, 2125573248, 2064430080, 2084769280, 2129391744, 2107445376, 1946102144, 2000204032, 2129084672, 2090926720, 2109267968, 2092312704, 2068152576, 2070944768, 2093225856, 2090595200, 2110532352, 2091776256, 2065233408, 2118154240, 2122267520, 2042141056, 1983808384, 2026817280, 2127233408, 2111968128, 2093850240, 2127255168, 2124948992, 2037085440, 1957875712, 2090527104], pads = [0, 0, 0, 0], quant_mode = #tpu<rq_mode QDM>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, rshift = [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10], strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x32x12x12x!quant.uniform<i8:f32, 0.0011358724409448817>>, tensor<32x32x1x1xsi8>, tensor<1x32x1x1xi32>) -> tensor<1x32x12x12x!quant.uniform<i8:f32, 0.0016324755905511811>> loc(#loc53)
    %54 = "top.Weight"() : () -> tensor<16x32x1x1xsi8> loc(#loc54)
    %55 = "top.Weight"() : () -> tensor<1x16x1x1xi32> loc(#loc55)
    %56 = "tpu.Conv2D"(%53, %54, %55) {coeff_merged = false, dilations = [1, 1], do_relu = true, do_winograd = false, dynweight_reorderd = false, group = 1 : i64, kernel_shape = [1, 1], kernel_zp = 0 : i64, multiplier = [2089160960, 2109828608, 2086049920, 2047949312, 2128894848, 2135749120, 2050810624, 2078633088, 2030535168, 2133005568, 2047925504, 2118825600, 2055700736, 2139968256, 2138356992, 2109927680], pads = [0, 0, 0, 0], quant_mode = #tpu<rq_mode QDM>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, rshift = [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9], strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x32x12x12x!quant.uniform<i8:f32, 0.0016324755905511811>>, tensor<16x32x1x1xsi8>, tensor<1x16x1x1xi32>) -> tensor<1x16x12x12x!quant.uniform<i8:f32, 0.0011609307086614172>> loc(#loc56)
    %57 = "top.Weight"() : () -> tensor<16x16x1x1xsi8> loc(#loc57)
    %58 = "top.Weight"() : () -> tensor<1x16x1x1xi32> loc(#loc58)
    %59 = "tpu.Conv2D"(%56, %57, %58) {coeff_merged = false, dilations = [1, 1], do_relu = true, do_winograd = false, dynweight_reorderd = false, group = 1 : i64, kernel_shape = [1, 1], kernel_zp = 0 : i64, multiplier = [2080364928, 2024419968, 2076602624, 2084404480, 1966129664, 1834006016, 2011548288, 1934562048, 2074224896, 1744258560, 1721032704, 1748787712, 2029793664, 2017562240, 2028701952, 2040148608], pads = [0, 0, 0, 0], quant_mode = #tpu<rq_mode QDM>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, rshift = [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10], strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x16x12x12x!quant.uniform<i8:f32, 0.0011609307086614172>>, tensor<16x16x1x1xsi8>, tensor<1x16x1x1xi32>) -> tensor<1x16x12x12x!quant.uniform<i8:f32, 0.0024052543307086613>> loc(#loc59)
    %60 = "top.Weight"() : () -> tensor<12x16x1x1xsi8> loc(#loc60)
    %61 = "top.Weight"() : () -> tensor<1x12x1x1xi32> loc(#loc61)
    %62 = "tpu.Conv2D"(%59, %60, %61) {coeff_merged = false, dilations = [1, 1], do_relu = false, do_winograd = false, dynweight_reorderd = false, group = 1 : i64, kernel_shape = [1, 1], kernel_zp = 0 : i64, multiplier = [1124095744, 1157749248, 1163896576, 1151128832, 1145421184, 1146779392, 2017476608, 1163146240, 1146340352, 1135196160, 2085781632, 1098949376], pads = [0, 0, 0, 0], quant_mode = #tpu<rq_mode QDM>, relu_limit = -1.000000e+00 : f64, round_mode = #tpu<round_mode HalfUp>, rshift = [8, 8, 8, 8, 8, 8, 9, 8, 8, 8, 9, 8], strides = [1, 1], support_compress = true, use_3ic_optimize = 0 : i64, weight_is_coeff = 1 : i64, with_bias = true} : (tensor<1x16x12x12x!quant.uniform<i8:f32, 0.0024052543307086613>>, tensor<12x16x1x1xsi8>, tensor<1x12x1x1xi32>) -> tensor<1x12x12x12x!quant.uniform<i8:f32, 0.0022237023622047243>> loc(#loc62)
    %63 = "tpu.Cast"(%62) {round_mode = #tpu<round_mode HalfAwayFromZero>, with_scale = true} : (tensor<1x12x12x12x!quant.uniform<i8:f32, 0.0022237023622047243>>) -> tensor<1x12x12x12xf32> loc(#loc63)
    %64 = "tpu.Permute"(%62, %0) {order = [0, 2, 3, 1]} : (tensor<1x12x12x12x!quant.uniform<i8:f32, 0.0022237023622047243>>, none) -> tensor<1x12x12x12x!quant.uniform<i8:f32, 0.0022237023622047243>> loc(#loc64)
    %65 = "tpu.Slice"(%64, %0, %0, %0, %0) {axes = [], ends = [1, 12, 12, 10], hasparamConvert_axes = [3], offset = [0, 0, 0, 0], steps = [1, 1, 1, 1]} : (tensor<1x12x12x12x!quant.uniform<i8:f32, 0.0022237023622047243>>, none, none, none, none) -> tensor<1x12x12x10x!quant.uniform<i8:f32, 0.0022237023622047243>> loc(#loc65)
    %66 = "tpu.Cast"(%65) {round_mode = #tpu<round_mode HalfAwayFromZero>, with_scale = true} : (tensor<1x12x12x10x!quant.uniform<i8:f32, 0.0022237023622047243>>) -> tensor<1x12x12x10xf32> loc(#loc66)
    %67 = "tpu.Slice"(%64, %0, %0, %0, %0) {axes = [], ends = [1, 12, 12, 2147482624], hasparamConvert_axes = [3], offset = [0, 0, 0, 10], steps = [1, 1, 1, 1]} : (tensor<1x12x12x12x!quant.uniform<i8:f32, 0.0022237023622047243>>, none, none, none, none) -> tensor<1x12x12x2x!quant.uniform<i8:f32, 0.0022237023622047243>> loc(#loc67)
    %68 = "tpu.Cast"(%67) {round_mode = #tpu<round_mode HalfAwayFromZero>, with_scale = true} : (tensor<1x12x12x2x!quant.uniform<i8:f32, 0.0022237023622047243>>) -> tensor<1x12x12x2xf32> loc(#loc68)
    return %66, %68, %63 : tensor<1x12x12x10xf32>, tensor<1x12x12x2xf32>, tensor<1x12x12x12xf32> loc(#loc)
  } loc(#loc)
} loc(#loc)
#loc1 = loc("input")
#loc2 = loc("input/Conv_96/activate/Relu_output_0_Relu_si8")
#loc3 = loc("/Conv_96/activate/Relu_output_0_Relu_filter_i8")
#loc4 = loc("/Conv_96/activate/Relu_output_0_Relu")
#loc5 = loc("/Conv_48/pool/MaxPool_output_0_MaxPool")
#loc6 = loc("/Conv_48/activate/Relu_output_0_Relu_filter_i8")
#loc7 = loc("/Conv_48/activate/Relu_output_0_Relu")
#loc8 = loc("/Conv_24_1/pool/MaxPool_output_0_MaxPool")
#loc9 = loc("/Conv_24_1/activate/Relu_output_0_Relu_filter_i8")
#loc10 = loc("/Conv_24_1/activate/Relu_output_0_Relu")
#loc11 = loc("/Conv_24_2/activate/Relu_output_0_Relu_filter_i8")
#loc12 = loc("/Conv_24_2/activate/Relu_output_0_Relu_bias_int32")
#loc13 = loc("/Conv_24_2/activate/Relu_output_0_Relu")
#loc14 = loc("/Conv_24_3/activate/Relu_output_0_Relu_filter_i8")
#loc15 = loc("/Conv_24_3/activate/Relu_output_0_Relu_bias_int32")
#loc16 = loc("/Conv_24_3/activate/Relu_output_0_Relu")
#loc17 = loc("/Conv_24_4/activate/Relu_output_0_Relu_filter_i8")
#loc18 = loc("/Conv_24_4/activate/Relu_output_0_Relu_bias_int32")
#loc19 = loc("/Conv_24_4/activate/Relu_output_0_Relu")
#loc20 = loc("/Conv_24_5/activate/Relu_output_0_Relu_filter_i8")
#loc21 = loc("/Conv_24_5/activate/Relu_output_0_Relu_bias_int32")
#loc22 = loc("/Conv_24_5/activate/Relu_output_0_Relu")
#loc23 = loc("/Conv_24_6/activate/Relu_output_0_Relu_filter_i8")
#loc24 = loc("/Conv_24_6/activate/Relu_output_0_Relu_bias_int32")
#loc25 = loc("/Conv_24_6/activate/Relu_output_0_Relu")
#loc26 = loc("/Conv_12_1/pool/MaxPool_output_0_MaxPool")
#loc27 = loc("/Conv_12_1/activate/Relu_output_0_Relu_filter_i8")
#loc28 = loc("/Conv_12_1/activate/Relu_output_0_Relu_bias_int32")
#loc29 = loc("/Conv_12_1/activate/Relu_output_0_Relu")
#loc30 = loc("/Conv_12_2/activate/Relu_output_0_Relu_filter_i8")
#loc31 = loc("/Conv_12_2/activate/Relu_output_0_Relu_bias_int32")
#loc32 = loc("/Conv_12_2/activate/Relu_output_0_Relu")
#loc33 = loc("/Conv_12_3/activate/Relu_output_0_Relu_filter_i8")
#loc34 = loc("/Conv_12_3/activate/Relu_output_0_Relu_bias_int32")
#loc35 = loc("/Conv_12_3/activate/Relu_output_0_Relu")
#loc36 = loc("/Conv_12_4/activate/Relu_output_0_Relu_filter_i8")
#loc37 = loc("/Conv_12_4/activate/Relu_output_0_Relu_bias_int32")
#loc38 = loc("/Conv_12_4/activate/Relu_output_0_Relu")
#loc39 = loc("/Conv_12_5/activate/Relu_output_0_Relu_filter_i8")
#loc40 = loc("/Conv_12_5/activate/Relu_output_0_Relu_bias_int32")
#loc41 = loc("/Conv_12_5/activate/Relu_output_0_Relu")
#loc42 = loc("/Conv_12_6/activate/Relu_output_0_Relu_filter_i8")
#loc43 = loc("/Conv_12_6/activate/Relu_output_0_Relu_bias_int32")
#loc44 = loc("/Conv_12_6/activate/Relu_output_0_Relu")
#loc45 = loc("/Conv_7_1/activate/Relu_output_0_Relu_filter_i8")
#loc46 = loc("/Conv_7_1/activate/Relu_output_0_Relu_bias_int32")
#loc47 = loc("/Conv_7_1/activate/Relu_output_0_Relu")
#loc48 = loc("/Conv_7_2/activate/Relu_output_0_Relu_filter_i8")
#loc49 = loc("/Conv_7_2/activate/Relu_output_0_Relu_bias_int32")
#loc50 = loc("/Conv_7_2/activate/Relu_output_0_Relu")
#loc51 = loc("/Conv_Res_1/activate/Relu_output_0_Relu_filter_i8")
#loc52 = loc("/Conv_Res_1/activate/Relu_output_0_Relu_bias_int32")
#loc53 = loc("/Conv_Res_1/activate/Relu_output_0_Relu")
#loc54 = loc("/Conv_Res_2/activate/Relu_output_0_Relu_filter_i8")
#loc55 = loc("/Conv_Res_2/activate/Relu_output_0_Relu_bias_int32")
#loc56 = loc("/Conv_Res_2/activate/Relu_output_0_Relu")
#loc57 = loc("/Conv_Res_3/activate/Relu_output_0_Relu_filter_i8")
#loc58 = loc("/Conv_Res_3/activate/Relu_output_0_Relu_bias_int32")
#loc59 = loc("/Conv_Res_3/activate/Relu_output_0_Relu")
#loc60 = loc("/Conv_Res_4/Conv_output_0_Conv_filter_i8")
#loc61 = loc("/Conv_Res_4/Conv_output_0_Conv_bias_int32")
#loc62 = loc("/Conv_Res_4/Conv_output_0_Conv")
#loc63 = loc("/Conv_Res_4/Conv_output_0_Conv_f32")
#loc64 = loc("/Transpose_output_0_Transpose")
#loc65 = loc("output_Slice")
#loc66 = loc("output_Slice_f32")
#loc67 = loc("667_Slice")
#loc68 = loc("667_Slice_f32")

