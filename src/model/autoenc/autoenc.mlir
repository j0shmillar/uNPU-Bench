#loc = loc(unknown)
module @autoenc attributes {module.FLOPs = 405184 : i64, module.chip = "ALL", module.platform = "ONNX", module.state = "TOP_F32", module.top_run_mode = "STATIC", module.weight_file = "autoenc_top_f32_all_weight.npz"} {
  func.func @main(%arg0: tensor<1x256x3xf32> loc(unknown)) -> tensor<1x256x3xf32> {
    %0 = "top.None"() : () -> none loc(#loc)
    %1 = "top.Input"(%arg0) {channel_format = "nchw", do_preprocess = true, keep_aspect_ratio = false, keep_ratio_mode = "letterbox", mean = [0.000000e+00, 0.000000e+00, 0.000000e+00], pad_type = "center", pad_value = 0 : i64, pixel_format = "bgr", scale = [1.000000e+00, 1.000000e+00, 1.000000e+00]} : (tensor<1x256x3xf32>) -> tensor<1x256x3xf32> loc(#loc1)
    %2 = "top.Weight"() : () -> tensor<128x256x1x1xf32> loc(#loc2)
    %3 = "top.Weight"() : () -> tensor<128xf32> loc(#loc3)
    %4 = "top.Conv"(%1, %2, %3) {dilations = [1, 1], do_relu = true, dynweight_reorderd = false, group = 1 : i64, kernel_shape = [1, 1], pads = [0, 0, 0, 0], relu_limit = -1.000000e+00 : f64, strides = [1, 1], weight_is_coeff = 1 : i64} : (tensor<1x256x3xf32>, tensor<128x256x1x1xf32>, tensor<128xf32>) -> tensor<1x128x3xf32> loc(#loc4)
    %5 = "top.Weight"() : () -> tensor<64x128x3x1xf32> loc(#loc5)
    %6 = "top.Weight"() : () -> tensor<64xf32> loc(#loc6)
    %7 = "top.Conv"(%4, %5, %6) {dilations = [1, 1], do_relu = true, dynweight_reorderd = false, group = 1 : i64, kernel_shape = [3, 1], pads = [0, 0, 0, 0], relu_limit = -1.000000e+00 : f64, strides = [1, 1], weight_is_coeff = 1 : i64} : (tensor<1x128x3xf32>, tensor<64x128x3x1xf32>, tensor<64xf32>) -> tensor<1x64x1xf32> loc(#loc7)
    %8 = "top.Reshape"(%7) {flatten_start_dim = -1 : i64, shape = [1, 64]} : (tensor<1x64x1xf32>) -> tensor<1x64xf32> loc(#loc8)
    %9 = "top.Weight"() : () -> tensor<64x32xf32> loc(#loc9)
    %10 = "top.Weight"() : () -> tensor<32xf32> loc(#loc10)
    %11 = "top.MatMul"(%8, %9, %10) {do_relu = true, hdim_is_batch = false, keep_dims = true, left_transpose = false, output_transpose = false, relu_limit = -1.000000e+00 : f64, right_transpose = false} : (tensor<1x64xf32>, tensor<64x32xf32>, tensor<32xf32>) -> tensor<1x32xf32> loc(#loc11)
    %12 = "top.Weight"() : () -> tensor<32x4xf32> loc(#loc12)
    %13 = "top.MatMul"(%11, %12, %0) {do_relu = false, hdim_is_batch = false, keep_dims = true, left_transpose = false, output_transpose = false, relu_limit = -1.000000e+00 : f64, right_transpose = false} : (tensor<1x32xf32>, tensor<32x4xf32>, none) -> tensor<1x4xf32> loc(#loc13)
    %14 = "top.Weight"() : () -> tensor<4x32xf32> loc(#loc14)
    %15 = "top.Weight"() : () -> tensor<32xf32> loc(#loc15)
    %16 = "top.MatMul"(%13, %14, %15) {do_relu = true, hdim_is_batch = false, keep_dims = true, left_transpose = false, output_transpose = false, relu_limit = -1.000000e+00 : f64, right_transpose = false} : (tensor<1x4xf32>, tensor<4x32xf32>, tensor<32xf32>) -> tensor<1x32xf32> loc(#loc16)
    %17 = "top.Weight"() : () -> tensor<32x96xf32> loc(#loc17)
    %18 = "top.Weight"() : () -> tensor<96xf32> loc(#loc18)
    %19 = "top.MatMul"(%16, %17, %18) {do_relu = true, hdim_is_batch = false, keep_dims = true, left_transpose = false, output_transpose = false, relu_limit = -1.000000e+00 : f64, right_transpose = false} : (tensor<1x32xf32>, tensor<32x96xf32>, tensor<96xf32>) -> tensor<1x96xf32> loc(#loc19)
    %20 = "top.Weight"() : () -> tensor<96x768xf32> loc(#loc20)
    %21 = "top.MatMul"(%19, %20, %0) {do_relu = false, hdim_is_batch = false, keep_dims = true, left_transpose = false, output_transpose = false, relu_limit = -1.000000e+00 : f64, right_transpose = false} : (tensor<1x96xf32>, tensor<96x768xf32>, none) -> tensor<1x768xf32> loc(#loc21)
    %22 = "top.Reshape"(%21) {flatten_start_dim = -1 : i64, shape = [1, 256, 3]} : (tensor<1x768xf32>) -> tensor<1x256x3xf32> loc(#loc22)
    return %22 : tensor<1x256x3xf32> loc(#loc)
  } loc(#loc)
} loc(#loc)
#loc1 = loc("input")
#loc2 = loc("103")
#loc3 = loc("105")
#loc4 = loc("/en_conv1/activate/Relu_output_0_Relu")
#loc5 = loc("107")
#loc6 = loc("109")
#loc7 = loc("/en_conv2/activate/Relu_output_0_Relu")
#loc8 = loc("/Reshape_output_0_Reshape")
#loc9 = loc("onnx::Gemm_240_fix")
#loc10 = loc("onnx::Gemm_241")
#loc11 = loc("/en_lin1/activate/Relu_output_0_Relu")
#loc12 = loc("onnx::MatMul_246")
#loc13 = loc("/en_lin2/MatMul_output_0_MatMul")
#loc14 = loc("onnx::Gemm_250_fix")
#loc15 = loc("onnx::Gemm_251")
#loc16 = loc("/de_lin1/activate/Relu_output_0_Relu")
#loc17 = loc("onnx::Gemm_255_fix")
#loc18 = loc("onnx::Gemm_256")
#loc19 = loc("/de_lin2/activate/Relu_output_0_Relu")
#loc20 = loc("onnx::MatMul_261")
#loc21 = loc("/out_lin/MatMul_output_0_MatMul")
#loc22 = loc("output_Reshape")

